{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in d:\\python3.10\\lib\\site-packages (4.9.2)\n",
      "Requirement already satisfied: selenium in d:\\python3.10\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: requests in d:\\python3.10\\lib\\site-packages (2.28.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in d:\\python3.10\\lib\\site-packages (from selenium) (1.26.15)\n",
      "Requirement already satisfied: trio~=0.17 in d:\\python3.10\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in d:\\python3.10\\lib\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in d:\\python3.10\\lib\\site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\python3.10\\lib\\site-packages (from requests) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\python3.10\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: attrs>=19.2.0 in d:\\python3.10\\lib\\site-packages (from trio~=0.17->selenium) (23.1.0)\n",
      "Requirement already satisfied: sortedcontainers in d:\\python3.10\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in d:\\python3.10\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: outcome in d:\\python3.10\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in d:\\python3.10\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in d:\\python3.10\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in d:\\python3.10\\lib\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in d:\\python3.10\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in d:\\python3.10\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in d:\\python3.10\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in d:\\python3.10\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml selenium requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from lxml import etree\n",
    "from selenium.webdriver.common.by import By\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_pages(number):\n",
    "    mo_urls = []\n",
    "    url = 'https://batdongsan.com.vn/nha-dat-ban-da-nang/p%s' % number\n",
    "    \n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('no-sandbox')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    # options.add_argument('headless')\n",
    "    # options.add_argument(\"--enable-javascript\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    driver.get(url)\n",
    "    m_urls = driver.find_elements(By.CLASS_NAME, 'js__product-link-for-product-id')\n",
    "    for m_url in m_urls:\n",
    "        mo_urls.append(m_url.get_attribute('href'))\n",
    "    driver.close()\n",
    "    return mo_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Phố Lý Thường Kiệt, Phường Thạch Thang, Hải Châu, Đà Nẵng',\n",
       " '256 tỷ',\n",
       " '1.500 m²',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_pages(url):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('no-sandbox')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    # options.add_argument('headless')\n",
    "    # options.add_argument(\"--enable-javascript\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    \n",
    "    # Address\n",
    "    try:\n",
    "        address = driver.find_element(By.CLASS_NAME, 'js__pr-address').text\n",
    "    except:\n",
    "        address = \"\"\n",
    "\n",
    "    # Price\n",
    "    try:\n",
    "        price = driver.find_element(By.XPATH, '/html/body/div[6]/div/div[2]/div[1]/div[3]/div[3]/div/div//*[text()[contains(.,\"Mức giá\")]]/..//*[contains(@class, \"re__pr-specs-content-item-value\")]').text\n",
    "    except:\n",
    "        price = \"\"\n",
    "\n",
    "    # Area\n",
    "    try:\n",
    "        area = driver.find_element(By.XPATH, '/html/body/div[6]/div/div[2]/div[1]/div[3]/div[3]/div/div//*[text()[contains(.,\"Diện tích\")]]/..//*[contains(@class, \"re__pr-specs-content-item-value\")]').text\n",
    "    except:\n",
    "        area = \"\"\n",
    "\n",
    "    # Room\n",
    "    try:\n",
    "        room = driver.find_element(By.XPATH, '/html/body/div[6]/div/div[2]/div[1]/div[3]/div[3]/div/div//*[text()[contains(.,\"Số phòng ngủ\")]]/..//*[contains(@class, \"re__pr-specs-content-item-value\")]').text\n",
    "    except:\n",
    "        room = \"\"\n",
    "\n",
    "    # Toilet\n",
    "    try:\n",
    "        toilet = driver.find_element(By.XPATH, '/html/body/div[6]/div/div[2]/div[1]/div[3]/div[3]/div/div//*[text()[contains(.,\"Số toilet\")]]/..//*[contains(@class, \"re__pr-specs-content-item-value\")]').text\n",
    "    except:\n",
    "        toilet = \"\"\n",
    "\n",
    "    # Floors\n",
    "    try:\n",
    "        floors = driver.find_element(By.XPATH, '/html/body/div[6]/div/div[2]/div[1]/div[3]/div[3]/div/div//*[text()[contains(.,\"Số tầng\")]]/..//*[contains(@class, \"re__pr-specs-content-item-value\")]').text\n",
    "    except:\n",
    "        floors = \"\"\n",
    "\n",
    "    # Facade\n",
    "    try:\n",
    "        facade = driver.find_element(By.XPATH, '/html/body/div[6]/div/div[2]/div[1]/div[3]/div[3]/div/div//*[text()[contains(.,\"Mặt tiền\")]]/..//*[contains(@class, \"re__pr-specs-content-item-value\")]').text\n",
    "    except:\n",
    "        facade = \"\"\n",
    "\n",
    "    # Road\n",
    "    try:\n",
    "        road = driver.find_element(By.XPATH, '/html/body/div[6]/div/div[2]/div[1]/div[3]/div[3]/div/div//*[text()[contains(.,\"Đường vào\")]]/..//*[contains(@class, \"re__pr-specs-content-item-value\")]').text\n",
    "    except:\n",
    "        road = \"\"\n",
    "\n",
    "    # Juridical\n",
    "    try:\n",
    "        juridical = driver.find_element(By.XPATH, '/html/body/div[6]/div/div[2]/div[1]/div[3]/div[3]/div/div//*[text()[contains(.,\"Pháp lý\")]]/..//*[contains(@class, \"re__pr-specs-content-item-value\")]').text\n",
    "    except:\n",
    "        juridical = \"\"\n",
    "\n",
    "    # Interior\n",
    "    try:\n",
    "        interior = driver.find_element(By.XPATH, '/html/body/div[6]/div/div[2]/div[1]/div[3]/div[3]/div/div//*[text()[contains(.,\"Nội thất\")]]/..//*[contains(@class, \"re__pr-specs-content-item-value\")]').text\n",
    "    except:\n",
    "        interior = \"\"\n",
    "\n",
    "    # House Direction\n",
    "    try:\n",
    "        hDirection = driver.find_element(By.XPATH, '/html/body/div[6]/div/div[2]/div[1]/div[3]/div[3]/div/div//*[text()[contains(.,\"Hướng nhà\")]]/..//*[contains(@class, \"re__pr-specs-content-item-value\")]').text\n",
    "    except:\n",
    "        hDirection = \"\"\n",
    "\n",
    "    # Balcony direction\n",
    "    try:\n",
    "        bDirection = driver.find_element(By.XPATH, '/html/body/div[6]/div/div[2]/div[1]/div[3]/div[3]/div/div//*[text()[contains(.,\"Hướng ban công\")]]/..//*[contains(@class, \"re__pr-specs-content-item-value\")]').text\n",
    "    except:\n",
    "        bDirection = \"\"\n",
    "\n",
    "    driver.close()\n",
    "    \n",
    "    return address, price, area, room, toilet, hDirection, bDirection, floors, facade, road, juridical, interior\n",
    "\n",
    "parse_pages(\"https://batdongsan.com.vn/ban-dat-pho-ly-thuong-kiet-phuong-thach-thang/chinh-chu-can-ban-duong-da-nang-1500m2-pr37449505\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(data, fileNum):\n",
    "    with open(f'lab5-{fileNum}.csv', 'a', encoding=\"utf-8\") as fp:\n",
    "        writer = csv.writer(fp)\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thread1():\n",
    "    for i in range(1, 10):\n",
    "        movie_urls = index_pages(i)\n",
    "        for movie_url in movie_urls:\n",
    "            result = parse_pages(movie_url)\n",
    "            save_results(result, 1)\n",
    "\n",
    "def thread2():\n",
    "    for i in range(11, 20):\n",
    "        movie_urls = index_pages(i)\n",
    "        for movie_url in movie_urls:\n",
    "            result = parse_pages(movie_url)\n",
    "            save_results(result, 2)\n",
    "\n",
    "def thread3():\n",
    "    for i in range(21, 30):\n",
    "        movie_urls = index_pages(i)\n",
    "        for movie_url in movie_urls:\n",
    "            result = parse_pages(movie_url)\n",
    "            save_results(result, 3)\n",
    "\n",
    "def thread4():\n",
    "    for i in range(31, 40):\n",
    "        movie_urls = index_pages(i)\n",
    "        for movie_url in movie_urls:\n",
    "            result = parse_pages(movie_url)\n",
    "            save_results(result, 4)\n",
    "\n",
    "def thread5():\n",
    "    for i in range(41, 50):\n",
    "        movie_urls = index_pages(i)\n",
    "        for movie_url in movie_urls:\n",
    "            result = parse_pages(movie_url)\n",
    "            save_results(result, 5)\n",
    "\n",
    "def thread6():\n",
    "    for i in range(51, 60):\n",
    "        movie_urls = index_pages(i)\n",
    "        for movie_url in movie_urls:\n",
    "            result = parse_pages(movie_url)\n",
    "            save_results(result, 6)\n",
    "    \n",
    "def thread7():\n",
    "    for i in range(61, 70):\n",
    "        movie_urls = index_pages(i)\n",
    "        for movie_url in movie_urls:\n",
    "            result = parse_pages(movie_url)\n",
    "            save_results(result, 7)\n",
    "\n",
    "def thread8():\n",
    "    for i in range(71, 80):\n",
    "        movie_urls = index_pages(i)\n",
    "        for movie_url in movie_urls:\n",
    "            result = parse_pages(movie_url)\n",
    "            save_results(result, 8)\n",
    "\n",
    "def thread9():\n",
    "    for i in range(81, 90):\n",
    "        movie_urls = index_pages(i)\n",
    "        for movie_url in movie_urls:\n",
    "            result = parse_pages(movie_url)\n",
    "            save_results(result, 9)\n",
    "\n",
    "def thread10():\n",
    "    for i in range(91, 100):\n",
    "        movie_urls = index_pages(i)\n",
    "        for movie_url in movie_urls:\n",
    "            result = parse_pages(movie_url)\n",
    "            save_results(result, 10)\n",
    "\n",
    "def thread11():\n",
    "    for i in range(101, 110):\n",
    "        movie_urls = index_pages(i)\n",
    "        for movie_url in movie_urls:\n",
    "            result = parse_pages(movie_url)\n",
    "            save_results(result, 11)\n",
    "\n",
    "def thread12():\n",
    "    for i in range(110, 120):\n",
    "        movie_urls = index_pages(i)\n",
    "        for movie_url in movie_urls:\n",
    "            result = parse_pages(movie_url)\n",
    "            save_results(result, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to interrupt the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.11' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "t1 = threading.Thread(target=thread1, args=())\n",
    "t2 = threading.Thread(target=thread2, args=())\n",
    "t3 = threading.Thread(target=thread3, args=())\n",
    "t4 = threading.Thread(target=thread4, args=())\n",
    "t5 = threading.Thread(target=thread5, args=())\n",
    "t6 = threading.Thread(target=thread6, args=())\n",
    "t7 = threading.Thread(target=thread7, args=())\n",
    "t8 = threading.Thread(target=thread8, args=())\n",
    "t9 = threading.Thread(target=thread9, args=())\n",
    "t10 = threading.Thread(target=thread10, args=())\n",
    "t11 = threading.Thread(target=thread11, args=())\n",
    "t12 = threading.Thread(target=thread12, args=())\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "t4.start()\n",
    "t5.start()\n",
    "t6.start()\n",
    "t7.start()\n",
    "t8.start()\n",
    "t9.start()\n",
    "t10.start()\n",
    "t11.start()\n",
    "t12.start()\n",
    "\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "t3.join()\n",
    "t4.join()\n",
    "t5.join()\n",
    "t6.join()\n",
    "t7.join()\n",
    "t8.join()\n",
    "t9.join()\n",
    "t10.join()\n",
    "t11.join()\n",
    "t12.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
